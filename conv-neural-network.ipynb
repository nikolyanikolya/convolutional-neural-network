{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "epochs_with_freezed_params = 2\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show\n",
    "from bokeh.models import LinearAxis, Range1d\n",
    "from itertools import chain\n",
    "\n",
    "class ConvNet(nn.Module): \n",
    "     def __init__(self): \n",
    "         super(ConvNet, self).__init__() \n",
    "         self.acc_list = []\n",
    "         self.loss_list = []\n",
    "         self.layer1 = nn.Sequential(nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2), \n",
    "            nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2))  \n",
    "         self.drop_out = nn.Dropout() \n",
    "         self.fc1 = nn.Linear(14 * 14 * 32, 500) \n",
    "         self.fc2 = nn.Linear(500, 10)\n",
    "         \n",
    "     def forward(self, x): \n",
    "         out = self.layer1(x) \n",
    "         out = out.reshape(out.size(0), -1) \n",
    "         out = self.drop_out(out) \n",
    "         out = self.fc1(out) \n",
    "         out = self.fc2(out) \n",
    "         return out      \n",
    "     \n",
    "     def train_model(self, train_loader, optimizer, loss_fn, freeze_conv_layers = False, need_unfreezing_action = False):\n",
    "         if freeze_conv_layers:\n",
    "             self.freeze_conv_layer_params()\n",
    "             \n",
    "         self.train()\n",
    "         for epoch in range(epochs):\n",
    "            if need_unfreezing_action:\n",
    "                self.try_to_unfreeze(epoch)\n",
    "            for index, (images, labels) in enumerate(train_loader):\n",
    "               outputs = self(images)\n",
    "               loss = loss_fn(outputs, labels)\n",
    "      \n",
    "               optimizer.zero_grad()\n",
    "               loss.backward()\n",
    "               optimizer.step()\n",
    "\n",
    "               total = labels.size(dim=0)\n",
    "               _, predicted = torch.max(outputs.data, dim=1)\n",
    "               correct = (predicted == labels).sum().item()\n",
    "\n",
    "               if index % 100 == 99:\n",
    "                  print(f\"Epoch [{epoch + 1}/{epochs}], Step [{index + 1}/{len(train_loader)}], Loss: {loss.item()}, Accuracy: {(correct / total) * 100}%\")  \n",
    "\n",
    "       \n",
    "     def test_model(self, test_loader, loss_fn):\n",
    "         self.eval()\n",
    "         with torch.no_grad():\n",
    "            matched_labels_count = 0\n",
    "            total_labels_count = 0\n",
    "            for images, labels in test_loader:\n",
    "                  outputs = self(images)\n",
    "                  loss = loss_fn(outputs, labels)\n",
    "                  \n",
    "                  self.loss_list.append(loss.item())\n",
    "\n",
    "                  _, prediction_labels = torch.max(outputs.data, dim=1)\n",
    "                  total_labels_count += labels.size(dim=0)\n",
    "                  matched_labels_count += (prediction_labels == labels).sum().item()\n",
    "                  \n",
    "                  self.acc_list.append(matched_labels_count / total_labels_count)\n",
    "\n",
    "            print(f\"Accuracy: {matched_labels_count / total_labels_count}\")\n",
    "            \n",
    "     def visualize(self):\n",
    "         p = figure(y_axis_label='Loss', width=1000, y_range=(0, 1), title='PyTorch ConvNet results')\n",
    "         p.extra_y_ranges = {'Accuracy': Range1d(start=0, end=100)}\n",
    "         p.add_layout(LinearAxis(y_range_name='Accuracy', axis_label='Accuracy (%)'), 'right')\n",
    "         p.line(np.arange(len(self.loss_list)), self.loss_list)\n",
    "         p.line(np.arange(len(self.loss_list)), np.array(self.acc_list) * 100, y_range_name='Accuracy', color='red')\n",
    "         show(p)\n",
    "\n",
    "     def freeze_conv_layer_params(self):\n",
    "         for param in chain(self.layer1.parameters(), self.layer2.parameters()):\n",
    "             param.requires_grad = False  \n",
    "\n",
    "     def unfreeze_conv_layer_params(self):\n",
    "         for param in chain(self.layer1.parameters(), self.layer2.parameters()):\n",
    "             param.requires_grad = True \n",
    "\n",
    "     def try_to_unfreeze(self, current_epoch):\n",
    "         if current_epoch > epochs_with_freezed_params:              \n",
    "            self.unfreeze_conv_layer_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "def train_test_split_loaders(train_dataset, test_dataset, batch_size):\n",
    "    return (\n",
    "            DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True), \n",
    "            DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        )\n",
    "\n",
    "trans = Compose([ToTensor()])\n",
    "\n",
    "train_mnist = MNIST(root=\"./MNIST\", train=True, transform=trans, download=True)\n",
    "test_mnist = MNIST(root=\"./MNIST\", train=False, transform=trans)\n",
    "\n",
    "train_fashion_mnist = FashionMNIST(root=\"./FashionMNIST\", train=True, transform=trans, download=True)\n",
    "test_fashion_mnist = FashionMNIST(root=\"./FashionMNIST\", train=False, transform=trans)\n",
    "\n",
    "batch_size = 100\n",
    "train_mnist_loader, test_mnist_loader = train_test_split_loaders(train_mnist, test_mnist, batch_size)\n",
    "train_fashion_mnist_loader, test_fashion_mnist_loader = train_test_split_loaders(train_fashion_mnist, test_fashion_mnist, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "mnist_model = ConvNet()\n",
    "mnist_optimizer = torch.optim.Adam(mnist_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_model = ConvNet()\n",
    "fashion_mnist_optimizer = torch.optim.Adam(fashion_mnist_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Step [100/600], Loss: 0.3662891387939453, Accuracy: 88.0%\n",
      "Epoch [1/6], Step [200/600], Loss: 0.17334100604057312, Accuracy: 97.0%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nikolya\\Desktop\\ML\\lab2\\lab2.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nikolya/Desktop/ML/lab2/lab2.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mnist_model\u001b[39m.\u001b[39;49mtrain_model(train_mnist_loader, mnist_optimizer, loss_fn)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikolya/Desktop/ML/lab2/lab2.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mnist_model\u001b[39m.\u001b[39mtest_model(test_mnist_loader, loss_fn)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikolya/Desktop/ML/lab2/lab2.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m torch\u001b[39m.\u001b[39msave(mnist_model\u001b[39m.\u001b[39mstate_dict(), \u001b[39m\"\u001b[39m\u001b[39m./MNIST_model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\nikolya\\Desktop\\ML\\lab2\\lab2.ipynb Cell 6\u001b[0m in \u001b[0;36mConvNet.train_model\u001b[1;34m(self, train_loader, optimizer, loss_fn, freeze_conv_layers, need_unfreezing_action)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikolya/Desktop/ML/lab2/lab2.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtry_to_unfreeze(epoch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikolya/Desktop/ML/lab2/lab2.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, (images, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nikolya/Desktop/ML/lab2/lab2.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m    outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(images)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikolya/Desktop/ML/lab2/lab2.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m    loss \u001b[39m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikolya/Desktop/ML/lab2/lab2.ipynb#W5sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m    optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\nikolya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\nikolya\\Desktop\\ML\\lab2\\lab2.ipynb Cell 6\u001b[0m in \u001b[0;36mConvNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikolya/Desktop/ML/lab2/lab2.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x): \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikolya/Desktop/ML/lab2/lab2.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer1(x) \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nikolya/Desktop/ML/lab2/lab2.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39;49mreshape(out\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m), \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikolya/Desktop/ML/lab2/lab2.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_out(out) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikolya/Desktop/ML/lab2/lab2.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(out) \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "mnist_model.train_model(train_mnist_loader, mnist_optimizer, loss_fn)\n",
    "mnist_model.test_model(test_mnist_loader, loss_fn)\n",
    "torch.save(mnist_model.state_dict(), \"./MNIST_model\")\n",
    "mnist_model.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Step [100/600], Loss: 0.649351954460144, Accuracy: 75.0%\n",
      "Epoch [1/6], Step [200/600], Loss: 0.5036018490791321, Accuracy: 80.0%\n",
      "Epoch [1/6], Step [300/600], Loss: 0.5208143591880798, Accuracy: 77.0%\n",
      "Epoch [1/6], Step [400/600], Loss: 0.5240964293479919, Accuracy: 81.0%\n",
      "Epoch [1/6], Step [500/600], Loss: 0.4630342125892639, Accuracy: 79.0%\n",
      "Epoch [1/6], Step [600/600], Loss: 0.3398512601852417, Accuracy: 84.0%\n",
      "Epoch [2/6], Step [100/600], Loss: 0.3794878423213959, Accuracy: 83.0%\n",
      "Epoch [2/6], Step [200/600], Loss: 0.46919986605644226, Accuracy: 86.0%\n",
      "Epoch [2/6], Step [300/600], Loss: 0.6601216793060303, Accuracy: 81.0%\n",
      "Epoch [2/6], Step [400/600], Loss: 0.5186206698417664, Accuracy: 82.0%\n",
      "Epoch [2/6], Step [500/600], Loss: 0.2892613410949707, Accuracy: 92.0%\n",
      "Epoch [2/6], Step [600/600], Loss: 0.48812881112098694, Accuracy: 83.0%\n",
      "Epoch [3/6], Step [100/600], Loss: 0.2348342388868332, Accuracy: 91.0%\n",
      "Epoch [3/6], Step [200/600], Loss: 0.2664889395236969, Accuracy: 89.0%\n",
      "Epoch [3/6], Step [300/600], Loss: 0.27899718284606934, Accuracy: 92.0%\n",
      "Epoch [3/6], Step [400/600], Loss: 0.28934913873672485, Accuracy: 90.0%\n",
      "Epoch [3/6], Step [500/600], Loss: 0.3366636633872986, Accuracy: 89.0%\n",
      "Epoch [3/6], Step [600/600], Loss: 0.3663514256477356, Accuracy: 88.0%\n",
      "Epoch [4/6], Step [100/600], Loss: 0.1884261667728424, Accuracy: 94.0%\n",
      "Epoch [4/6], Step [200/600], Loss: 0.3800184726715088, Accuracy: 90.0%\n",
      "Epoch [4/6], Step [300/600], Loss: 0.3621334731578827, Accuracy: 84.0%\n",
      "Epoch [4/6], Step [400/600], Loss: 0.34056374430656433, Accuracy: 88.0%\n",
      "Epoch [4/6], Step [500/600], Loss: 0.14099815487861633, Accuracy: 97.0%\n",
      "Epoch [4/6], Step [600/600], Loss: 0.32681405544281006, Accuracy: 88.0%\n",
      "Epoch [5/6], Step [100/600], Loss: 0.37567955255508423, Accuracy: 86.0%\n",
      "Epoch [5/6], Step [200/600], Loss: 0.20717491209506989, Accuracy: 94.0%\n",
      "Epoch [5/6], Step [300/600], Loss: 0.2363177090883255, Accuracy: 91.0%\n",
      "Epoch [5/6], Step [400/600], Loss: 0.38014769554138184, Accuracy: 87.0%\n",
      "Epoch [5/6], Step [500/600], Loss: 0.2776184380054474, Accuracy: 91.0%\n",
      "Epoch [5/6], Step [600/600], Loss: 0.3319123387336731, Accuracy: 87.0%\n",
      "Epoch [6/6], Step [100/600], Loss: 0.12948773801326752, Accuracy: 98.0%\n",
      "Epoch [6/6], Step [200/600], Loss: 0.3773638904094696, Accuracy: 84.0%\n",
      "Epoch [6/6], Step [300/600], Loss: 0.1866324543952942, Accuracy: 93.0%\n",
      "Epoch [6/6], Step [400/600], Loss: 0.2227906733751297, Accuracy: 90.0%\n",
      "Epoch [6/6], Step [500/600], Loss: 0.14648118615150452, Accuracy: 94.0%\n",
      "Epoch [6/6], Step [600/600], Loss: 0.3195592164993286, Accuracy: 87.0%\n",
      "Accuracy: 0.9037\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist_model.train_model(train_fashion_mnist_loader, fashion_mnist_optimizer, loss_fn)\n",
    "fashion_mnist_model.test_model(test_fashion_mnist_loader, loss_fn)\n",
    "torch.save(fashion_mnist_model.state_dict(), \"./FashionMNIST_model\")\n",
    "fashion_mnist_model.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Step [100/600], Loss: 2.308201313018799, Accuracy: 6.0%\n",
      "Epoch [1/6], Step [200/600], Loss: 2.2895514965057373, Accuracy: 12.0%\n",
      "Epoch [1/6], Step [300/600], Loss: 2.317331075668335, Accuracy: 9.0%\n",
      "Epoch [1/6], Step [400/600], Loss: 2.3062806129455566, Accuracy: 8.0%\n",
      "Epoch [1/6], Step [500/600], Loss: 2.3023929595947266, Accuracy: 12.0%\n",
      "Epoch [1/6], Step [600/600], Loss: 2.3020949363708496, Accuracy: 13.0%\n",
      "Epoch [2/6], Step [100/600], Loss: 2.3016440868377686, Accuracy: 9.0%\n",
      "Epoch [2/6], Step [200/600], Loss: 2.306906223297119, Accuracy: 11.0%\n",
      "Epoch [2/6], Step [300/600], Loss: 2.3007352352142334, Accuracy: 7.000000000000001%\n",
      "Epoch [2/6], Step [400/600], Loss: 2.3010094165802, Accuracy: 13.0%\n",
      "Epoch [2/6], Step [500/600], Loss: 2.311950922012329, Accuracy: 8.0%\n",
      "Epoch [2/6], Step [600/600], Loss: 2.31272292137146, Accuracy: 11.0%\n",
      "Epoch [3/6], Step [100/600], Loss: 2.308354616165161, Accuracy: 9.0%\n",
      "Epoch [3/6], Step [200/600], Loss: 2.288602352142334, Accuracy: 11.0%\n",
      "Epoch [3/6], Step [300/600], Loss: 2.314417839050293, Accuracy: 5.0%\n",
      "Epoch [3/6], Step [400/600], Loss: 2.3152647018432617, Accuracy: 14.000000000000002%\n",
      "Epoch [3/6], Step [500/600], Loss: 2.3061511516571045, Accuracy: 10.0%\n",
      "Epoch [3/6], Step [600/600], Loss: 2.305760622024536, Accuracy: 6.0%\n",
      "Epoch [4/6], Step [100/600], Loss: 2.314584493637085, Accuracy: 10.0%\n",
      "Epoch [4/6], Step [200/600], Loss: 2.3145084381103516, Accuracy: 6.0%\n",
      "Epoch [4/6], Step [300/600], Loss: 2.3142647743225098, Accuracy: 12.0%\n",
      "Epoch [4/6], Step [400/600], Loss: 2.3121750354766846, Accuracy: 10.0%\n",
      "Epoch [4/6], Step [500/600], Loss: 2.297966241836548, Accuracy: 15.0%\n",
      "Epoch [4/6], Step [600/600], Loss: 2.3299601078033447, Accuracy: 10.0%\n",
      "Epoch [5/6], Step [100/600], Loss: 2.303828239440918, Accuracy: 10.0%\n",
      "Epoch [5/6], Step [200/600], Loss: 2.3122854232788086, Accuracy: 14.000000000000002%\n",
      "Epoch [5/6], Step [300/600], Loss: 2.291630506515503, Accuracy: 18.0%\n",
      "Epoch [5/6], Step [400/600], Loss: 2.2899057865142822, Accuracy: 11.0%\n",
      "Epoch [5/6], Step [500/600], Loss: 2.3228719234466553, Accuracy: 10.0%\n",
      "Epoch [5/6], Step [600/600], Loss: 2.318730354309082, Accuracy: 11.0%\n",
      "Epoch [6/6], Step [100/600], Loss: 2.3118045330047607, Accuracy: 10.0%\n",
      "Epoch [6/6], Step [200/600], Loss: 2.299765110015869, Accuracy: 9.0%\n",
      "Epoch [6/6], Step [300/600], Loss: 2.301692247390747, Accuracy: 12.0%\n",
      "Epoch [6/6], Step [400/600], Loss: 2.299940586090088, Accuracy: 12.0%\n",
      "Epoch [6/6], Step [500/600], Loss: 2.305250883102417, Accuracy: 13.0%\n",
      "Epoch [6/6], Step [600/600], Loss: 2.3215339183807373, Accuracy: 11.0%\n",
      "Accuracy: 0.071\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist_model = ConvNet()\n",
    "fashion_mnist_optimizer = torch.optim.Adam(mnist_model.parameters(), lr=learning_rate)\n",
    "fashion_mnist_model.train_model(train_fashion_mnist_loader, fashion_mnist_optimizer, loss_fn)\n",
    "fashion_mnist_model.test_model(test_fashion_mnist_loader, loss_fn)\n",
    "torch.save(fashion_mnist_model.state_dict(), \"./FashionMNIST_model_with_mnist_params\")\n",
    "fashion_mnist_model.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Step [100/600], Loss: 2.3373935222625732, Accuracy: 10.0%\n",
      "Epoch [1/6], Step [200/600], Loss: 2.320798873901367, Accuracy: 6.0%\n",
      "Epoch [1/6], Step [300/600], Loss: 2.341214179992676, Accuracy: 5.0%\n",
      "Epoch [1/6], Step [400/600], Loss: 2.3510124683380127, Accuracy: 8.0%\n",
      "Epoch [1/6], Step [500/600], Loss: 2.355327844619751, Accuracy: 7.000000000000001%\n",
      "Epoch [1/6], Step [600/600], Loss: 2.3380839824676514, Accuracy: 15.0%\n",
      "Epoch [2/6], Step [100/600], Loss: 2.32938289642334, Accuracy: 12.0%\n",
      "Epoch [2/6], Step [200/600], Loss: 2.325033187866211, Accuracy: 10.0%\n",
      "Epoch [2/6], Step [300/600], Loss: 2.303967237472534, Accuracy: 17.0%\n",
      "Epoch [2/6], Step [400/600], Loss: 2.290449619293213, Accuracy: 15.0%\n",
      "Epoch [2/6], Step [500/600], Loss: 2.293976068496704, Accuracy: 11.0%\n",
      "Epoch [2/6], Step [600/600], Loss: 2.334038257598877, Accuracy: 8.0%\n",
      "Epoch [3/6], Step [100/600], Loss: 2.3173398971557617, Accuracy: 11.0%\n",
      "Epoch [3/6], Step [200/600], Loss: 2.3274481296539307, Accuracy: 7.000000000000001%\n",
      "Epoch [3/6], Step [300/600], Loss: 2.3114709854125977, Accuracy: 12.0%\n",
      "Epoch [3/6], Step [400/600], Loss: 2.353703022003174, Accuracy: 9.0%\n",
      "Epoch [3/6], Step [500/600], Loss: 2.329373598098755, Accuracy: 10.0%\n",
      "Epoch [3/6], Step [600/600], Loss: 2.3287785053253174, Accuracy: 9.0%\n",
      "Epoch [4/6], Step [100/600], Loss: 2.334946393966675, Accuracy: 9.0%\n",
      "Epoch [4/6], Step [200/600], Loss: 2.314690589904785, Accuracy: 10.0%\n",
      "Epoch [4/6], Step [300/600], Loss: 2.349287509918213, Accuracy: 16.0%\n",
      "Epoch [4/6], Step [400/600], Loss: 2.3734540939331055, Accuracy: 8.0%\n",
      "Epoch [4/6], Step [500/600], Loss: 2.3259453773498535, Accuracy: 13.0%\n",
      "Epoch [4/6], Step [600/600], Loss: 2.327850103378296, Accuracy: 8.0%\n",
      "Epoch [5/6], Step [100/600], Loss: 2.3626902103424072, Accuracy: 9.0%\n",
      "Epoch [5/6], Step [200/600], Loss: 2.3503262996673584, Accuracy: 10.0%\n",
      "Epoch [5/6], Step [300/600], Loss: 2.3267648220062256, Accuracy: 9.0%\n",
      "Epoch [5/6], Step [400/600], Loss: 2.3289289474487305, Accuracy: 8.0%\n",
      "Epoch [5/6], Step [500/600], Loss: 2.332242727279663, Accuracy: 12.0%\n",
      "Epoch [5/6], Step [600/600], Loss: 2.3164358139038086, Accuracy: 14.000000000000002%\n",
      "Epoch [6/6], Step [100/600], Loss: 2.292226791381836, Accuracy: 12.0%\n",
      "Epoch [6/6], Step [200/600], Loss: 2.3114819526672363, Accuracy: 11.0%\n",
      "Epoch [6/6], Step [300/600], Loss: 2.3266525268554688, Accuracy: 8.0%\n",
      "Epoch [6/6], Step [400/600], Loss: 2.3386361598968506, Accuracy: 12.0%\n",
      "Epoch [6/6], Step [500/600], Loss: 2.331727981567383, Accuracy: 11.0%\n",
      "Epoch [6/6], Step [600/600], Loss: 2.3488364219665527, Accuracy: 7.000000000000001%\n",
      "Accuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist_model = ConvNet()\n",
    "fashion_mnist_optimizer = torch.optim.Adam(mnist_model.parameters(), lr=learning_rate)\n",
    "fashion_mnist_model.train_model(train_fashion_mnist_loader, fashion_mnist_optimizer, loss_fn, freeze_conv_layers=True)\n",
    "fashion_mnist_model.test_model(test_fashion_mnist_loader, loss_fn)\n",
    "torch.save(fashion_mnist_model.state_dict(), \"./FashionMNIST_model_with_mnist_params_freezed\")\n",
    "fashion_mnist_model.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Step [100/600], Loss: 2.3158626556396484, Accuracy: 7.000000000000001%\n",
      "Epoch [1/6], Step [200/600], Loss: 2.312411069869995, Accuracy: 6.0%\n",
      "Epoch [1/6], Step [300/600], Loss: 2.302726984024048, Accuracy: 8.0%\n",
      "Epoch [1/6], Step [400/600], Loss: 2.3084301948547363, Accuracy: 6.0%\n",
      "Epoch [1/6], Step [500/600], Loss: 2.295276403427124, Accuracy: 11.0%\n",
      "Epoch [1/6], Step [600/600], Loss: 2.296238422393799, Accuracy: 12.0%\n",
      "Epoch [2/6], Step [100/600], Loss: 2.307976722717285, Accuracy: 7.000000000000001%\n",
      "Epoch [2/6], Step [200/600], Loss: 2.308424472808838, Accuracy: 6.0%\n",
      "Epoch [2/6], Step [300/600], Loss: 2.3003296852111816, Accuracy: 13.0%\n",
      "Epoch [2/6], Step [400/600], Loss: 2.295710563659668, Accuracy: 9.0%\n",
      "Epoch [2/6], Step [500/600], Loss: 2.329542636871338, Accuracy: 2.0%\n",
      "Epoch [2/6], Step [600/600], Loss: 2.3218984603881836, Accuracy: 6.0%\n",
      "Epoch [3/6], Step [100/600], Loss: 2.314357042312622, Accuracy: 7.000000000000001%\n",
      "Epoch [3/6], Step [200/600], Loss: 2.314119577407837, Accuracy: 11.0%\n",
      "Epoch [3/6], Step [300/600], Loss: 2.3056557178497314, Accuracy: 4.0%\n",
      "Epoch [3/6], Step [400/600], Loss: 2.2950849533081055, Accuracy: 11.0%\n",
      "Epoch [3/6], Step [500/600], Loss: 2.303910970687866, Accuracy: 12.0%\n",
      "Epoch [3/6], Step [600/600], Loss: 2.3108017444610596, Accuracy: 6.0%\n",
      "Epoch [4/6], Step [100/600], Loss: 2.2935280799865723, Accuracy: 9.0%\n",
      "Epoch [4/6], Step [200/600], Loss: 2.3151159286499023, Accuracy: 10.0%\n",
      "Epoch [4/6], Step [300/600], Loss: 2.313819408416748, Accuracy: 9.0%\n",
      "Epoch [4/6], Step [400/600], Loss: 2.29870867729187, Accuracy: 13.0%\n",
      "Epoch [4/6], Step [500/600], Loss: 2.3060801029205322, Accuracy: 12.0%\n",
      "Epoch [4/6], Step [600/600], Loss: 2.327697515487671, Accuracy: 8.0%\n",
      "Epoch [5/6], Step [100/600], Loss: 2.3011810779571533, Accuracy: 10.0%\n",
      "Epoch [5/6], Step [200/600], Loss: 2.310650110244751, Accuracy: 11.0%\n",
      "Epoch [5/6], Step [300/600], Loss: 2.2816429138183594, Accuracy: 14.000000000000002%\n",
      "Epoch [5/6], Step [400/600], Loss: 2.319378614425659, Accuracy: 9.0%\n",
      "Epoch [5/6], Step [500/600], Loss: 2.3117730617523193, Accuracy: 13.0%\n",
      "Epoch [5/6], Step [600/600], Loss: 2.2952029705047607, Accuracy: 11.0%\n",
      "Epoch [6/6], Step [100/600], Loss: 2.3055124282836914, Accuracy: 6.0%\n",
      "Epoch [6/6], Step [200/600], Loss: 2.309741497039795, Accuracy: 4.0%\n",
      "Epoch [6/6], Step [300/600], Loss: 2.320415496826172, Accuracy: 8.0%\n",
      "Epoch [6/6], Step [400/600], Loss: 2.300596237182617, Accuracy: 7.000000000000001%\n",
      "Epoch [6/6], Step [500/600], Loss: 2.303130865097046, Accuracy: 13.0%\n",
      "Epoch [6/6], Step [600/600], Loss: 2.311408758163452, Accuracy: 9.0%\n",
      "Accuracy: 0.062\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist_model = ConvNet()\n",
    "fashion_mnist_optimizer = torch.optim.Adam(mnist_model.parameters(), lr=learning_rate)\n",
    "fashion_mnist_model.train_model(train_fashion_mnist_loader, fashion_mnist_optimizer, loss_fn, freeze_conv_layers=True, \\\n",
    "                                need_unfreezing_action=True)\n",
    "fashion_mnist_model.test_model(test_fashion_mnist_loader, loss_fn)\n",
    "torch.save(fashion_mnist_model.state_dict(), \"./FashionMNIST_model_with_mnist_params_unfreezed\")\n",
    "fashion_mnist_model.visualize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
